{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3531b5bf-f0d7-43c3-9de8-65cf65be0b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c19ff52-44fa-448e-92ca-8bb24133b5ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c20d9bcdcd849a7b707d173a8f42380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cad8c92dcc147dcb97a3880f18c9172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# convert PIL to tensor cost lots of time\n",
    "for i in tqdm(ca['pngfilename'].iloc[:5000]):\n",
    "    test_image = Image.open(source_dir + i)\n",
    "    \n",
    "for i in tqdm(ca['pngfilename'].iloc[:5000]):\n",
    "    test_image = Image.open(source_dir + i)\n",
    "    tensor_image = torchvision.transforms.functional.pil_to_tensor(test_image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "669836b9-ded4-4717-aa5b-a0d122e81a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3188a20600554321b462d28f8765be18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# convert PIL to tensor then save as .pth\n",
    "for i in tqdm(ca['pngfilename'].iloc[:5000]):\n",
    "    test_image = Image.open(source_dir + i)\n",
    "    tensor_image = torchvision.transforms.functional.pil_to_tensor(test_image)\n",
    "    torch.save(tensor_image, f'image_pth/{i.replace(\"png\", \"pth\")}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6389ae67-9373-4fcf-8ece-9a297c7e4150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b55589edb34844e587dd0e3728d8178a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load .pth need less time\n",
    "for i in tqdm(ca['pngfilename'].iloc[:5000]):\n",
    "    tesor_image = torch.load(f'image_pth/{i.replace(\"png\", \"pth\")}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac6a8187-4de7-46c0-9e12-9c8a4ae4a765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86d3db8aa9a74ce8a855935b6f7f6a1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double check because pth can loose or distor raw information.\n",
    "# Of course PIL->tensor and PIL->tensor->load tensor are same\n",
    "# png have more informations like meta, but what we need is only pixel informations with tensor form.\n",
    "# .pth is enough to do so.\n",
    "acc_list = list()\n",
    "for i in tqdm(ca['pngfilename'].iloc[:5000]):\n",
    "    pth_image = torch.load(f'image_pth/{i.replace(\"png\", \"pth\")}')\n",
    "    test_image = Image.open(source_dir + i)\n",
    "    tensor_image = torchvision.transforms.functional.pil_to_tensor(test_image)\n",
    "    acc = (pth_image == tensor_image).sum() / tensor_image.shape[0] / tensor_image.shape[1] / tensor_image.shape[2]\n",
    "    acc_list.append(acc)\n",
    "np.mean(acc_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
